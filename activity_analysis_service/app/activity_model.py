import os
import torch
import logging
from shared.enhancing_models import VideoEnhancer
from qwen_vl_utils import process_vision_info
from transformers import AutoProcessor, AutoModelForVision2Seq
from transformers import Qwen2VLForConditionalGeneration, Qwen2VLProcessor
import traceback

# ØªØ¹Ø·ÙŠÙ„ Ø§Ù„ØªØ­Ø°ÙŠØ±Ø§Øª ØºÙŠØ± Ø§Ù„Ø¶Ø±ÙˆØ±ÙŠØ©
os.environ['HF_HUB_DISABLE_SYMLINKS_WARNING'] = '1'
os.environ['HF_HUB_DISABLE_PROGRESS_BARS'] = '1'
os.environ['TRANSFORMERS_VERBOSITY'] = 'error'

logger = logging.getLogger(__name__)
video_enhancer = VideoEnhancer()


def move_to_device(obj, device):
    """Ù†Ù‚Ù„ ÙƒÙ„ tensors Ø¯Ø§Ø®Ù„ dict/list/tensor Ø¥Ù„Ù‰ Ù†ÙØ³ Ø§Ù„Ø¬Ù‡Ø§Ø²"""
    if torch.is_tensor(obj):
        return obj.to(device)
    elif isinstance(obj, dict):
        return {k: move_to_device(v, device) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [move_to_device(v, device) for v in obj]
    else:
        return obj


class ActivityRecognizer:
    def __init__(self):
        try:
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØªÙˆÙØ± GPU Ø£ÙˆÙ„Ø§Ù‹
            if torch.cuda.is_available():
                self.device = torch.device("cuda")
                logger.info("ğŸ¯ ØªÙ… Ø§ÙƒØªØ´Ø§Ù GPUØŒ Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ­Ù…ÙŠÙ„ Ø¹Ù„Ù‰ CUDA...")
            else:
                self.device = torch.device("cpu")
                logger.info("âš™ï¸  Ù„Ù… ÙŠØªÙ… Ø§ÙƒØªØ´Ø§Ù GPUØŒ Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ­Ù…ÙŠÙ„ Ø¹Ù„Ù‰ CPU...")

            # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬ Ø£ÙˆÙ„Ø§Ù‹
            logger.info("ğŸ“¥ Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ Ù…Ø¹Ø§Ù„Ø¬ Qwen2-VL...")
            self.qwen2_vl_proc = AutoProcessor.from_pretrained(
                "Qwen/Qwen2-VL-2B-Instruct",
                trust_remote_code=True
            )

            # Ø«Ù… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
            logger.info("ğŸ“¥ Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Qwen2-VL...")
            self.qwen2_vl_model = Qwen2VLForConditionalGeneration.from_pretrained(
                "Qwen/Qwen2-VL-2B-Instruct",
                torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,
                device_map="auto",
                trust_remote_code=True
            )

            # ÙˆØ¶Ø¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙÙŠ ÙˆØ¶Ø¹ Ø§Ù„ØªÙ‚ÙŠÙŠÙ…
            self.qwen2_vl_model.eval()

            logger.info(f"âœ… ØªÙ… ØªÙ‡ÙŠØ¦Ø© ActivityRecognizer Ø¨Ù†Ø¬Ø§Ø­ Ø¹Ù„Ù‰ {self.device}")

        except Exception as e:
            logger.error(f"âŒ ÙØ´Ù„ ØªÙ‡ÙŠØ¦Ø© ActivityRecognizer: {e}")
            logger.error(traceback.format_exc())
            self.qwen2_vl_model = None
            self.qwen2_vl_proc = None
            self.device = None

    def recognize_activity(self, prompt: str, video_path: str, fsp: float, pixels_size: int,
                           max_new_tokens: int = 600, temperature: float = 0.3,
                           top_p: float = 0.9, top_k: int = 50, do_sample: bool = True,
                           enable_enhancement: bool = False, enhancement_strength: int = 2):

        if self.qwen2_vl_model is None or self.qwen2_vl_proc is None:
            return "âŒ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ØºÙŠØ± Ù…ØªØ§Ø­ Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…"

        try:
            # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù‚ÙŠÙ… None
            max_new_tokens = max_new_tokens if max_new_tokens is not None else 600
            temperature = temperature if temperature is not None else 0.3
            top_p = top_p if top_p is not None else 0.9
            top_k = top_k if top_k is not None else 50
            do_sample = do_sample if do_sample is not None else True

            logger.info("âœ… Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø¹Ø¯ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©:")
            logger.info(
                f"max_new_tokens={max_new_tokens}, temperature={temperature}, top_p={top_p}, top_k={top_k}, do_sample={do_sample}")

            # ØªØ­Ø³ÙŠÙ† Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…Ø·Ù„ÙˆØ¨Ø§Ù‹
            final_video_path = video_path
            if enable_enhancement:
                logger.info("ğŸ¨ ØªÙØ¹ÙŠÙ„ ØªØ­Ø³ÙŠÙ† Ø¬ÙˆØ¯Ø© Ø§Ù„ÙÙŠØ¯ÙŠÙˆ...")
                final_video_path = video_enhancer.enhance_video(video_path, enhancement_strength)
                logger.info(f"ğŸ“¹ Ù…Ø³Ø§Ø± Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ: {final_video_path}")

            # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„
            messages = [
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "video",
                            "video": final_video_path,
                            "max_pixels": pixels_size * pixels_size,
                            "fps": fsp,
                        },
                        {"type": "text", "text": prompt},
                    ],
                }
            ]

            # ØªÙØ±ÙŠØº Ø§Ù„Ø°Ø§ÙƒØ±Ø©
            if torch.cuda.is_available():
                torch.cuda.empty_cache()

            # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª
            text = self.qwen2_vl_proc.apply_chat_template(
                messages, tokenize=False, add_generation_prompt=True
            )
            image_inputs, video_inputs = process_vision_info(messages)

            inputs = self.qwen2_vl_proc(
                text=[text],
                images=image_inputs,
                videos=video_inputs,
                padding=True,
                return_tensors="pt",
            )

            # Ù†Ù‚Ù„ Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª Ø¥Ù„Ù‰ Ø§Ù„Ø¬Ù‡Ø§Ø² Ø§Ù„Ù…Ù†Ø§Ø³Ø¨
            inputs = {k: v.to(self.device) for k, v in inputs.items()}

            # Ø§Ù„Ø§Ø³ØªØ¯Ù„Ø§Ù„
            with torch.no_grad():
                generated_ids = self.qwen2_vl_model.generate(
                    **inputs,
                    max_new_tokens=max_new_tokens,
                    temperature=temperature,
                    top_p=top_p,
                    top_k=top_k,
                    do_sample=do_sample,
                    pad_token_id=self.qwen2_vl_proc.tokenizer.eos_token_id
                )

            # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø®Ø±Ø¬Ø§Øª
            generated_ids_trimmed = [
                out_ids[len(in_ids):] for in_ids, out_ids in zip(inputs["input_ids"], generated_ids)
            ]

            output_text = self.qwen2_vl_proc.batch_decode(
                generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False
            )

            # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø°Ø§ÙƒØ±Ø©
            del inputs, generated_ids, generated_ids_trimmed
            if torch.cuda.is_available():
                torch.cuda.empty_cache()

            return output_text[0]

        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Ø´Ø§Ø·: {e}")
            logger.error(traceback.format_exc())
            return f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„: {str(e)}"

    def cleanup(self):
        """ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…ÙˆØ§Ø±Ø¯"""
        try:
            if hasattr(self, 'qwen2_vl_model') and self.qwen2_vl_model is not None:
                del self.qwen2_vl_model
            if hasattr(self, 'qwen2_vl_proc') and self.qwen2_vl_proc is not None:
                del self.qwen2_vl_proc

            if torch.cuda.is_available():
                torch.cuda.empty_cache()

            logger.info("ğŸ§¹ ØªÙ… ØªÙ†Ø¸ÙŠÙ Ù…ÙˆØ§Ø±Ø¯ ActivityRecognizer")
        except Exception as e:
            logger.error(f"âš ï¸ Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªÙ†Ø¸ÙŠÙ: {e}")
