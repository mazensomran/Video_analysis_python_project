import subprocess
import torch
import whisper
from pathlib import Path
import logging
from shared.config import MODEL_CONFIG
import tempfile
import os

logger = logging.getLogger(__name__)
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')


class SpeechRecognizer:
    def __init__(self):
        self.models_dir =  Path("../")
        self.model_name = "base"
        self.device = device
        self.model = None
        self._load_model("base")

    def _load_model(self, model_name):
        """ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ø§Ù…"""
        try:
            logger.info(f"ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ø§Ù… ({self.model_name}) Ø¹Ù„Ù‰ {self.device}...")
            available_models = MODEL_CONFIG["available_whisper_models"]
            if model_name not in available_models:
                print(f"âš ï¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ {model_name} ØºÙŠØ± Ù…ØªØ§Ø­ØŒ Ø§Ø³ØªØ®Ø¯Ø§Ù… 'base' Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù†Ù‡")
                model_name = "base"

            self.model = whisper.load_model(
                model_name,
                download_root=str(self.models_dir / "whisper"),
                device=self.device
            )

            if self.model is not None:
                logger.info(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ø§Ù… Ø¹Ù„Ù‰ {self.device}")
            else:
                logger.error("âŒ ÙØ´Ù„ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ø§Ù…")

        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ø§Ù…: {e}")
            self.model = None

    def transcribe_audio(self, video_path: str) -> dict:
        """ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª Ø¥Ù„Ù‰ Ù†Øµ"""
        if self.model is None:
            return {"text": "", "language": "unknown", "confidence": 0.0}

        try:
            if not Path(video_path).exists():
                logger.error(f"âŒ Ù…Ù„Ù Ø§Ù„ÙÙŠØ¯ÙŠÙˆ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯: {video_path}")
                return {"text": "", "language": "unknown", "confidence": 0.0}

            with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as audio_temp_file:
                audio_path = audio_temp_file.name

            if not self.extract_audio(video_path, audio_path):
                logger.error(f"âŒ ÙØ´Ù„ ÙÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ØµÙˆØª Ù…Ù† Ø§Ù„ÙÙŠØ¯ÙŠÙˆ: {video_path}")
                return {"text": "", "language": "unknown", "confidence": 0.0}

            if torch.cuda.is_available():
                torch.cuda.empty_cache()

            logger.info("ğŸµ Ø¬Ø§Ø±ÙŠ ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª Ø¥Ù„Ù‰ Ù†Øµ...")
            result = self.model.transcribe(audio_path, fp16=torch.cuda.is_available())

            # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø«Ù‚Ø© Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠÙ‹Ø§
            confidence = 0.9  # Ù‚ÙŠÙ…Ø© Ø§ÙØªØ±Ø§Ø¶ÙŠØ©
            if "segments" in result and result["segments"]:
                segment_confidences = [segment.get("avg_logprob", 0.0) for segment in
                                       result["segments"]]  # Ù…Ø«Ø§Ù„: Ø§Ø³ØªØ®Ø¯Ø§Ù… avg_logprob
                if segment_confidences:
                    confidence = sum(segment_confidences) / len(segment_confidences)  # Ù…ØªÙˆØ³Ø· Ø§Ù„Ø«Ù‚Ø©

            transcription_result = {
                "text": result["text"],
                "language": result.get("language", "unknown"),
                "confidence": confidence,  # Ø§Ù„Ø¢Ù† Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠ
                "segments": result.get("segments", [])
            }
            return transcription_result
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø£Ùˆ Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ù†Øµ: {e}")
            return {"text": "", "language": "unknown", "confidence": 0.0}
        finally:
            if os.path.exists(audio_path):
                os.unlink(audio_path)

    def extract_audio(self, video_path: str, output_audio_path: str) -> bool:
        """Ø¯Ø§Ù„Ø© Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ØµÙˆØª Ù…Ù† Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ù…Ø¹ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØªÙˆÙØ± FFmpeg"""
        try:
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØªÙˆÙØ± FFmpeg Ø£ÙˆÙ„Ø§Ù‹
            try:
                subprocess.run(['ffmpeg', '-version'], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
            except FileNotFoundError:
                logger.error("âŒ FFmpeg ØºÙŠØ± Ù…Ø«Ø¨Øª. ÙŠØ±Ø¬Ù‰ Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ØªØ«Ø¨ÙŠØªÙ‡.")
                return False

            command = [
                'ffmpeg', '-i', video_path, '-q:a', '0', '-map', 'a',
                output_audio_path, '-y', '-loglevel', 'error'
            ]
            result = subprocess.run(command, capture_output=True, text=True)
            if result.returncode == 0:
                logger.info(f"âœ… ØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ØµÙˆØª Ø¨Ù†Ø¬Ø§Ø­: {output_audio_path}")
                return True
            else:
                logger.error(f"âŒ ÙØ´Ù„ ÙÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ØµÙˆØª: {result.stderr}")
                return False
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ØµÙˆØª: {e}")
            return False

    def cleanup(self):
        """ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…ÙˆØ§Ø±Ø¯"""
        self.model = None
        logger.info("ğŸ§¹ ØªÙ… ØªÙ†Ø¸ÙŠÙ Ù…ÙˆØ§Ø±Ø¯ SpeechRecognizer")

