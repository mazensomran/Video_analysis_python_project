import subprocess
import torch
import whisper
from pathlib import Path
import logging
from shared.config import MODEL_CONFIG
import tempfile
import os

logger = logging.getLogger(__name__)
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')


class SpeechRecognizer:
    def __init__(self):

        self.models_dir = Path("./models")
        self.models_dir.mkdir(exist_ok=True, parents=True)  # âœ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ø§Ù‹
        self.model_name = "base"
        self.device = device
        self.model = None
        self._load_model("base")

    def _load_model(self, model_name):
        """ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ø§Ù…"""
        try:
            logger.info(f"ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ø§Ù… ({model_name}) Ø¹Ù„Ù‰ {self.device}...")
            available_models = MODEL_CONFIG["available_whisper_models"]
            if model_name not in available_models:
                logger.warning(f"âš ï¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ {model_name} ØºÙŠØ± Ù…ØªØ§Ø­ØŒ Ø§Ø³ØªØ®Ø¯Ø§Ù… 'base' Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù†Ù‡")
                model_name = "base"

            # âœ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ø¹ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø£ÙØ¶Ù„ Ù„Ù„Ø£Ø®Ø·Ø§Ø¡
            self.model = whisper.load_model(
                model_name,
                download_root=str(self.models_dir / "whisper"),
                device=self.device
            )

            if self.model is not None:
                logger.info(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ø§Ù… Ø¹Ù„Ù‰ {self.device}")
            else:
                logger.error("âŒ ÙØ´Ù„ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ø§Ù…")
                raise Exception("ÙØ´Ù„ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬")

        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ø§Ù…: {e}", exc_info=True)
            self.model = None
            raise  # âœ… Ø¥Ø¹Ø§Ø¯Ø© Ø±ÙØ¹ Ø§Ù„Ø§Ø³ØªØ«Ù†Ø§Ø¡

    def transcribe_audio(self, video_path: str) -> dict:
        """ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª Ø¥Ù„Ù‰ Ù†Øµ"""
        if self.model is None:
            logger.error("âŒ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ØºÙŠØ± Ù…Ø­Ù…Ù„")
            return {"text": "", "language": "unknown", "confidence": 0.0}

        audio_path = None
        try:
            video_path_obj = Path(video_path)
            if not video_path_obj.exists():
                logger.error(f"âŒ Ù…Ù„Ù Ø§Ù„ÙÙŠØ¯ÙŠÙˆ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯: {video_path}")
                return {"text": "", "language": "unknown", "confidence": 0.0}

            logger.info(f"ğŸµ Ø¨Ø¯Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ÙÙŠØ¯ÙŠÙˆ: {video_path}")

            # âœ… Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù ØµÙˆØªÙŠ Ù…Ø¤Ù‚Øª
            with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as audio_temp_file:
                audio_path = audio_temp_file.name

            logger.info("ğŸ”Š Ø¬Ø§Ø±ÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ØµÙˆØª Ù…Ù† Ø§Ù„ÙÙŠØ¯ÙŠÙˆ...")
            if not self.extract_audio(video_path, audio_path):
                logger.error(f"âŒ ÙØ´Ù„ ÙÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ØµÙˆØª Ù…Ù† Ø§Ù„ÙÙŠØ¯ÙŠÙˆ: {video_path}")
                return {"text": "", "language": "unknown", "confidence": 0.0}

            # âœ… Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ù…Ù„Ù Ø§Ù„ØµÙˆØªÙŠ ÙˆØ­Ø¬Ù…Ù‡
            audio_file_size = Path(audio_path).stat().st_size
            if audio_file_size == 0:
                logger.error("âŒ Ø§Ù„Ù…Ù„Ù Ø§Ù„ØµÙˆØªÙŠ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬ ÙØ§Ø±Øº")
                return {"text": "", "language": "unknown", "confidence": 0.0}

            logger.info(f"âœ… ØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ØµÙˆØª Ø¨Ù†Ø¬Ø§Ø­ØŒ Ø§Ù„Ø­Ø¬Ù…: {audio_file_size} bytes")

            if torch.cuda.is_available():
                torch.cuda.empty_cache()

            logger.info("ğŸµ Ø¬Ø§Ø±ÙŠ ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª Ø¥Ù„Ù‰ Ù†Øµ...")
            result = self.model.transcribe(audio_path, fp16=torch.cuda.is_available())
            logger.info(f"âœ… ØªÙ… Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ø¨Ù†Ø¬Ø§Ø­ØŒ Ø§Ù„Ù†Øµ: {len(result['text'])} Ø­Ø±Ù")

            # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø«Ù‚Ø© Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠÙ‹Ø§
            confidence = 0.9
            if "segments" in result and result["segments"]:
                segment_confidences = [segment.get("avg_logprob", 0.0) for segment in result["segments"]]
                if segment_confidences:
                    confidence = sum(segment_confidences) / len(segment_confidences)

            transcription_result = {
                "text": result["text"].strip(),
                "language": result.get("language", "unknown"),
                "confidence": confidence,
                "segments": result.get("segments", [])
            }

            logger.info(f"ğŸ“Š Ù†ØªÙŠØ¬Ø© Ø§Ù„ØªØ­ÙˆÙŠÙ„: Ù„ØºØ©={transcription_result['language']}, Ø«Ù‚Ø©={confidence:.2f}")
            return transcription_result

        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø£Ùˆ Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ù†Øµ: {e}", exc_info=True)
            return {"text": "", "language": "unknown", "confidence": 0.0}
        finally:
            # âœ… ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø¤Ù‚Øª
            if audio_path and os.path.exists(audio_path):
                try:
                    os.unlink(audio_path)
                    logger.info("ğŸ§¹ ØªÙ… ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ù„Ù Ø§Ù„ØµÙˆØªÙŠ Ø§Ù„Ù…Ø¤Ù‚Øª")
                except Exception as e:
                    logger.warning(f"âš ï¸ ÙØ´Ù„ ÙÙŠ Ø­Ø°Ù Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø¤Ù‚Øª: {e}")

    def extract_audio(self, video_path: str, output_audio_path: str) -> bool:
        """Ø¯Ø§Ù„Ø© Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ØµÙˆØª Ù…Ù† Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ù…Ø¹ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØªÙˆÙØ± FFmpeg"""
        try:
            # âœ… Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØªÙˆÙØ± FFmpeg Ø£ÙˆÙ„Ø§Ù‹
            try:
                result = subprocess.run(['ffmpeg', '-version'],
                                        stdout=subprocess.PIPE,
                                        stderr=subprocess.PIPE,
                                        timeout=10)
                if result.returncode != 0:
                    logger.error("âŒ FFmpeg ØºÙŠØ± Ù…Ø«Ø¨Øª Ø£Ùˆ Ø¨Ù‡ Ù…Ø´ÙƒÙ„Ø©")
                    return False
                logger.info("âœ… FFmpeg Ù…ØªÙˆÙØ±")
            except (FileNotFoundError, subprocess.TimeoutExpired) as e:
                logger.error(f"âŒ FFmpeg ØºÙŠØ± Ù…Ø«Ø¨Øª Ø£Ùˆ ØºÙŠØ± Ù‚Ø§Ø¨Ù„ Ù„Ù„ÙˆØµÙˆÙ„: {e}")
                return False

            # âœ… Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø£Ù…Ø± Ø£ÙƒØ«Ø± Ù…Ø±ÙˆÙ†Ø© Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ØµÙˆØª
            command = [
                'ffmpeg',
                '-i', video_path,
                '-vn',  # Ù„Ø§ ÙÙŠØ¯ÙŠÙˆ
                '-acodec', 'pcm_s16le',  # ØªØ±Ù…ÙŠØ² ØµÙˆØªÙŠ Ù…Ù†Ø§Ø³Ø¨
                '-ar', '16000',  # Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø¹ÙŠÙ†Ø©
                '-ac', '1',  # mono
                '-y',  # overwrite
                '-loglevel', 'error',
                output_audio_path
            ]

            logger.info(f"ğŸ”§ ØªØ´ØºÙŠÙ„ Ø£Ù…Ø± FFmpeg: {' '.join(command)}")
            result = subprocess.run(command, capture_output=True, text=True, timeout=60)

            if result.returncode == 0:
                logger.info(f"âœ… ØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ØµÙˆØª Ø¨Ù†Ø¬Ø§Ø­: {output_audio_path}")
                return True
            else:
                logger.error(f"âŒ ÙØ´Ù„ ÙÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ØµÙˆØª: {result.stderr}")
                return False

        except subprocess.TimeoutExpired:
            logger.error("âŒ Ø§Ù†ØªÙ‡Øª Ø§Ù„Ù…Ù‡Ù„Ø© ÙÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ØµÙˆØª")
            return False
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ØµÙˆØª: {e}")
            return False

    def cleanup(self):
        """ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…ÙˆØ§Ø±Ø¯"""
        if self.model is not None:
            del self.model
            self.model = None
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        logger.info("ğŸ§¹ ØªÙ… ØªÙ†Ø¸ÙŠÙ Ù…ÙˆØ§Ø±Ø¯ SpeechRecognizer")
